{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKUWgOJwMzli"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DVl3UV0BMzlj"
   },
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commom variables\n",
    "samples = 20 # 20 samples per contamination level (from experiments)\n",
    "cu_levels = [0,500,1000,2000,4000]      #Levels of Cu contamination\n",
    "cr_levels = [0, 100, 500, 800, 1000]    #Levels of Cr contamination\n",
    "features = int(22015)     #22015 wavelength features\n",
    "wvl_in, wvl_end = 219, 877 #initial and final wavelength "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkS61LQJMzlw"
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data from Excel file\n",
    "#Comment the lines depending on what metal is being analysed\n",
    "#temp = pd.read_excel('copper.xlsx')    #Execution quite long\n",
    "#metal_levels = cu_levels\n",
    "temp = pd.read_excel('chromium.xlsx')    #Execution quite long\n",
    "metal_levels = cr_levels\n",
    "\n",
    "levels=len(metal_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leLJFp0bMzl0"
   },
   "source": [
    "### Read the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ouik4QLPMzl0",
    "outputId": "06b84fd8-65f0-4cab-916c-919d6bed58ec"
   },
   "outputs": [],
   "source": [
    "data_numpy = temp.to_numpy()\n",
    "metal = np.transpose(data_numpy)       #spreadsheet is comming in columms\n",
    "\n",
    "wavelengths = metal[0,1:]   #save the wavelengths \n",
    "data=metal[1:,:]       #data is all the spreadsheet but the first row (wavelengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKw8HAQYMzl1"
   },
   "source": [
    "#### Divide data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7_D4vbXMzl2",
    "outputId": "c58a87c4-987f-4896-e656-aa133762d1ea"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=43)\n",
    "\n",
    "#train_set, valid_set = train_test_split(train_full,test_size=10,random_state=43)\n",
    "\n",
    "y_train = train_set[:,0]     # y_train is the first columm of train_set\n",
    "y_test=test_set[:,0]       # y_test is the first columm of test_set\n",
    "#y_valid=valid_set[:,0]       # y_valid is the first columm of valid_set\n",
    "\n",
    "X_train=train_set[:,1:]    # X_train is all r,c of train_set but the first c\n",
    "X_test=test_set[:,1:]      # X_test is all r,c of test_set but the first c\n",
    "#X_valid=valid_set[:,1:]      # X_valid is all r,c of valid_set but the first c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ie035jH_Mzl3"
   },
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_CHsZjMsMzmH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3293619155883789"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=623,max_depth=15)\n",
    "\n",
    "start_1 = time.time()\n",
    "forest_clf.fit(X_train, y_train) #Not saved?\n",
    "end_1_st_6 = time.time()\n",
    "\n",
    "#Compute the time differences for each subset\n",
    "time_1 = end_1_st_6 - start_1\n",
    "time_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osmR8IexMzmJ"
   },
   "source": [
    "#### Getting the cross validation confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1C71WT7TMzmK",
    "outputId": "e0dd4151-ec62-455d-b71f-960dda1db53a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  2,  0,  0,  0],\n",
       "       [ 0, 17,  0,  0,  0],\n",
       "       [ 0,  0, 16,  2,  0],\n",
       "       [ 0,  0,  2, 16,  0],\n",
       "       [ 0,  0,  0,  0, 15]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CV process\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_cv_pred = cross_val_predict(forest_clf, X_train, y_train, cv=3) #no the definitive model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat_RF_cv = confusion_matrix(y_train, y_cv_pred)\n",
    "conf_mat_RF_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KyWS9LuzMzmL",
    "outputId": "5b434c89-760e-424d-d9bd-45f60a640d61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RF cross-validation accuracy score on train set is 0.925\n"
     ]
    }
   ],
   "source": [
    "#Validate model with test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Acc_cv = accuracy_score(y_train, y_cv_pred)\n",
    "print(\"The RF cross-validation accuracy score on train set is\", Acc_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "o2DVeVvhMzmM",
    "outputId": "e24a9172-01d2-4745-fc0d-352fd1d745d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 0, 0, 0, 0],\n",
       "       [0, 3, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 5]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test evaluation\n",
    "y_test_pred = forest_clf.predict(X_test)\n",
    "\n",
    "conf_mat_RF_test = confusion_matrix(y_test, y_test_pred)\n",
    "conf_mat_RF_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZS4DLnkMzmM",
    "outputId": "26dd7528-3702-4c4f-caf6-d45ad111daaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RF accuracy score on test set is 0.9\n"
     ]
    }
   ],
   "source": [
    "Acc_test = accuracy_score(y_test, y_test_pred)\n",
    "print(\"The RF accuracy score on test set is\", Acc_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jj68ZubNMzmN"
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11vpIUuLMzmP",
    "outputId": "5946e547-cd8f-4dab-ddf0-77c86d6e35f3"
   },
   "outputs": [],
   "source": [
    "# Computing mean and std deviation of each feature for each contamination level \n",
    "ini=0\n",
    "last=samples-1\n",
    "meansT, stdT = np.zeros((features,levels)), np.zeros((features,levels))\n",
    "for x in range(levels):\n",
    "    sub_array=data[ini:last,1:]\n",
    "    meansT[:,x]=sub_array.mean(axis=0)      #compute column means\n",
    "    stdT[:,x]=sub_array.std(axis=0)      #compute column standard deviation\n",
    "    ini=last+1\n",
    "    last=last+samples\n",
    "means = meansT.transpose()\n",
    "std = stdT.transpose()\n",
    "#print(means.shape)\n",
    "#print(std.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQ-E7ALFMzmQ",
    "outputId": "a8aedcdb-8923-4a4c-beed-3bca36833c6a"
   },
   "source": [
    "### Generating new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VjffyECjMzmR"
   },
   "outputs": [],
   "source": [
    "Newsamples = 100   #Edit this number to have more samples per each level of contamination\n",
    "last=Newsamples-1\n",
    "ini = 0\n",
    "newData=np.zeros((Newsamples*levels,features+1))  #Assuming 5 levels of contamination\n",
    "for x in range(levels):\n",
    "    newData[ini:last+1,0]= np.tile(metal_levels[x],Newsamples)\n",
    "    newData[ini:last+1,1:] = np.random.normal(means[x,:],std[x,:],size=(Newsamples,features))\n",
    "    ini=ini+Newsamples\n",
    "    last=last+Newsamples    \n",
    "#newData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the new Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate X and y fromm datasets\n",
    "\n",
    "y_newData = newData[:,0]     # y is the first columm of the set\n",
    "y_data = data[:,0]      \n",
    "\n",
    "X_newData = newData[:,1:]    # X is all r,c of the set but the first c\n",
    "X_data = data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8129701614379883\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "start_1 = time.time()\n",
    "forest_clf.fit(X_newData, y_newData) \n",
    "end_1_st_6 = time.time()\n",
    "\n",
    "#Compute the time differences for each subset\n",
    "time_1 = end_1_st_6 - start_1\n",
    "print(time_1)\n",
    "\n",
    "#Execute a cross validation\n",
    "#y_cv_nD_pred = cross_val_predict(forest_clf, X_newData, y_newData, cv=3) #no the definitive model\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#conf_mat_RF_nD = confusion_matrix(y_newData, y_cv_nD_pred)\n",
    "#conf_mat_RF_nD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "o2DVeVvhMzmM",
    "outputId": "e24a9172-01d2-4745-fc0d-352fd1d745d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  0,  0,  0,  0],\n",
       "       [ 0, 20,  0,  0,  0],\n",
       "       [ 0,  0, 19,  1,  0],\n",
       "       [ 0,  0,  3, 17,  0],\n",
       "       [ 0,  0,  0,  0, 20]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Real data evaluation model\n",
    "\n",
    "y_data_pred = forest_clf.predict(X_data)\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "conf_mat_RF_data = confusion_matrix(y_data, y_data_pred)\n",
    "conf_mat_RF_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZS4DLnkMzmM",
    "outputId": "26dd7528-3702-4c4f-caf6-d45ad111daaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RF accuracy score on real data set is 0.96\n"
     ]
    }
   ],
   "source": [
    "Acc_data = accuracy_score(y_data, y_data_pred)\n",
    "print(\"The RF accuracy score on real data set is\", Acc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22015,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Plot the most important features\n",
    "sorted_idx = forest_clf.feature_importances_.argsort()[::-1]\n",
    "sorted_idx.shape\n",
    "#plt.barh(wavelengths[sorted_idx], forest_clf.feature_importances_[sorted_idx])\n",
    "#plt.xlabel(\"Random Forest Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22015,)\n",
      "(22015,)\n",
      "0.9533385003993999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Choose the most important features\n",
    "feat = 500  #Edit this number to change the number of the most important features chosen\n",
    "print(sorted_idx.shape)\n",
    "print(forest_clf.feature_importances_.shape)\n",
    "most_imp_feat=sorted_idx[0:feat]\n",
    "print(sum(forest_clf.feature_importances_[most_imp_feat]))\n",
    "most_imp_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostImp_feat=wavelengths[sorted_idx[0:feat]]\n",
    "mostImp_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data from Excel file\n",
    "#temp = pd.read_excel('cu_NIST.xlsx')    #Execution quite long\n",
    "temp = pd.read_excel('cr_NIST.xlsx')    #Execution quite long\n",
    "nist_col = 1/10*temp.to_numpy()\n",
    "nist = np.transpose(nist_col)       #spreadsheet is comming in columms\n",
    "\n",
    "#wavelengths = metal[0,1:]   #save the wavelengths \n",
    "#data=metal[1:,:]       #data is all the spreadsheet but the first row (wavelengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ouik4QLPMzl0",
    "outputId": "06b84fd8-65f0-4cab-916c-919d6bed58ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent, i, good = 0.001, 0, 0\n",
    "for x in nist_col:               #nist list\n",
    "    for y in mostImp_feat:       #models wavelength\n",
    "        if y < x*(1+percent) and y > x*(1-percent):\n",
    "            good=good+1\n",
    "            break\n",
    "            \n",
    "good        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 239)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(nist.shape)\n",
    "print(mostImp_feat.shape)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Project_v0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
